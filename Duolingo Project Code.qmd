---
title: "Duolingo Project Code"
author: "Michael Chrzan, Alexa Sparks, Tracy Li"
format: html
editor: visual
---

# Setup

## Libraries

Which libraries will we use and why?

```{r libraries}
library(tidyverse)
library(skimr)
library(naniar)
library(gt)
library(MASS)
library(caret)
library(vip)
library(rpart.plot)
library(randomForest)
library(FactoMineR)
library(factoextra)
library(corrplot)
library(mclust)
library(DescTools)
library(stats)
library(dendextend)
library(ggrepel)
library(tidytext)
library(rgl)
library(plotly)
```

## Import Data

```{r import-data}
duodata <- read_csv("data_flatformat.csv")
```

# Explore Data

```{r view-data}
#glimpse(duodata)
#duoskim <- skim(duodata)
duoskim
```

## Original Missing Data

```{r viz-missing}
#Setting sample since these packaged functions throw errors for large data
set.seed(1234)
duosample <- sample_n(duodata, 2622956/54)

vis_miss(duosample, 
         show_perc = TRUE) 
miss_var_summary(duosample)

duosample_mis <- duosample |> 
  dplyr::select(prompt, time, client, format, session)

gg_miss_var(duosample_mis)
gg_miss_var(duosample_mis, 
            facet = client, 
            show_pct = TRUE)
gg_miss_var(duosample_mis, 
            facet = format, 
            show_pct = TRUE)
gg_miss_var(duosample_mis, 
            facet = session, 
            show_pct = TRUE)
gg_miss_upset(duosample_mis)

```

```{r examine-mis-prompt}
#Examining Missiningness Related to Prompt and Time with Other Variables #Is all the missing prompt data in format? Appears so (NOTE, not the sample now, full dataset) 
#Prompt 
duodata |> 
  dplyr::select(prompt, format, session, client) |> 
  group_by(format, session, client) |> 
  miss_var_summary() |> 
  arrange(desc(pct_miss)) 

#Time 
duodata |> 
  dplyr::select(time, format, session, client) |> 
  group_by(format, session, client) |> 
  miss_var_summary() |> 
  arrange(desc(pct_miss))
```

```{r examine-session-format-distribution}

duodata |> 
  group_by(session, format) |> 
  summarize(n = n())

#NOTE: NOT evenly distributed formats within session types. Reverse translate by far the most common
```

# Data Cleaning

```{r remove-mis-remaining}
duodata <- duodata |> 
  dplyr::select(-prompt) |> 
  na.omit()
```

```{r viz-variable-dist}
duodata |> 
  pivot_longer(cols = c(part_of_speech, client, session, format), 
               names_to = "variable", 
               values_to = "value") |> 
  ggplot() + geom_bar(aes(value)) + 
  facet_wrap(. ~ variable, scales = "free") + 
  coord_flip() 

duodata |> 
  pivot_longer(cols = c(dependency_label, countries), 
               names_to = "variable", 
               values_to = "value") |> 
  ggplot() + 
  geom_bar(aes(value)) + 
  facet_wrap(. ~ variable, scales = "free") + 
  coord_flip() 

duodata |> 
  pivot_longer(cols = where(is.numeric), 
               names_to = "variable", 
               values_to = "value") |> 
  ggplot() + 
  geom_histogram(aes(value)) + 
  facet_wrap(. ~ variable, scales = "free") 

#Should we include folks at 0 days?

```

```{r check-data}
distinct(duodata, countries) 

#Checking Time Values 
summary(duodata$time)
duodata |> 
  ggplot(aes(x = time)) + 
  geom_histogram()

  #Checking average user time
duodata |> 
  group_by(user) |> 
  mutate(avg_time = mean(time)) |> 
  dplyr::select(user, avg_time, time) |> 
  arrange(desc(time))
      #QTNA: Why don't some users have an avg_time but have time? #Number of Users with ONLY        less than 1 day, 52 - resulting in ~30000 rows 

  #This shows that 60 users used the app for longer than 14 hours in one session
duodata |> 
  group_by(user) |> 
  summarize(max_time = max(time)) |> 
  arrange(desc(max_time)) |> 
  filter(max_time < 50400)


#Large Dependency Edge Head Value (originally 442 rows larger than 10)
summary(duodata$dependency_edge_head)
duodata |> 
  ggplot(aes(x = dependency_edge_head)) + 
  geom_histogram()



#Users who used the app less than 1 day
one_days <- duodata |> 
  group_by(user) |> 
  mutate(max_days = max(days)) |> 
  ungroup() |> 
  filter(max_days < 1) 

n_distinct(one_days$user) 
#Curious if there's any patterns in how these folks use it rather than others. 
#Michael noticed from the histogram that users trail off as days increases.

#Proportion of Correct Responses, 14.62% 
sum(duodata$label == 1)/sum(duodata$label == 0)

```

```{r clean-data}
#Removing instances with logging issues (time < 1) as noted in the documentation and time > 3 hours for reasonability
duodata <- duodata |> 
  filter(time > 0) |> 
  filter(time < 10800)
```

```{r variable-creation}
#AVERAGES

#Averge Accuracy, Session Time, and Days for each User for their entire time 
duodata <- duodata |> 
  group_by(user) |> 
  mutate(avg_total_accuracy = mean(label), 
         avg_session_time = mean(time)) |> 
  ungroup()
  #dplyr::select(user, session_id, exercise_id, contains('avg')) 


#Averge Number of Exercises per Session (get and remove Number of Exercises by Session_id)
duodata <- duodata |> 
  group_by(session_id) |> 
  mutate(num_exercises_this_session = n_distinct(exercise_index)) |> 
  ungroup() |> 
  group_by(user) |>
  mutate(avg_exercises_per_session = mean(num_exercises_this_session)) |>
  ungroup() |> 
  dplyr::select(-num_exercises_this_session)
  #dplyr::select(user, session_id, num_session_exercises, avg_exer_per_session) 


#Averge Number of Sessions per Day (get and remove Number of Sessions By Day) 
duodata <- duodata |> 
  mutate(days_count = floor(days)) |> 
  group_by(user, days_count) |> 
  mutate(num_sessions_user_in_day = n_distinct(session_id)) |> 
  ungroup() |> 
  group_by(user) |> 
  mutate(avg_num_sessions_in_day = mean(num_sessions_user_in_day)) |> 
  dplyr::select(-days_count, -num_sessions_user_in_day)
  #dplyr::select(user, days_count, session_id, num_sessions_this_day, avg_num_sessions) 


#Average Exercise Accuracy by User 
user_ex_acc <- duodata |> 
  group_by(user, exercise_id) |> 
  summarize(avg_accuracy_by_exercise = mean(label), 
            .groups = 'keep') |>
  ungroup() |> 
  dplyr::select(-exercise_id) |>
  group_by(user) |> 
  summarize(avg_exercise_accuracy = mean(avg_accuracy_by_exercise), 
            .groups = 'keep') |> 
  ungroup()

duodata <- left_join(duodata, user_ex_acc, 
                     by = join_by(user))

rm(user_ex_acc)


#Average Overall Session Accuracy
user_sess_acc <- duodata |> 
  group_by(user, session_id) |> 
  summarize(avg_accuracy_by_session = mean(label), 
            .groups = 'keep') |>
  ungroup() |> 
  dplyr::select(-session_id) |>
  group_by(user) |> 
  summarize(avg_session_accuracy = mean(avg_accuracy_by_session), 
            .groups = 'keep') |> 
  ungroup()

duodata <- left_join(duodata, user_sess_acc, 
                     by = join_by(user))

rm(user_sess_acc)

  
#Average Session Accuracy by Type
  #Average Test Accuracy
user_test_acc <- duodata |> 
  filter(session == 'test') |> 
  group_by(user) |> 
  summarize(avg_test_accuracy = mean(label), 
            .groups = 'keep') |> 
  ungroup()

duodata <- left_join(duodata, user_test_acc, 
                     by = join_by(user)) |>
  mutate(avg_test_accuracy = if_else(is.na(avg_test_accuracy),
                                           avg_session_accuracy,
                                           avg_test_accuracy))

rm(user_test_acc)

  #Average Lesson Accuracy
user_lesson_acc <- duodata |> 
  filter(session == 'lesson') |> 
  group_by(user) |> 
  summarize(avg_lesson_accuracy = mean(label), 
            .groups = 'keep') |> 
  ungroup()

duodata <- left_join(duodata, user_lesson_acc, 
          by = join_by(user)) |>
  mutate(avg_lesson_accuracy = if_else(is.na(avg_lesson_accuracy),
                                             avg_session_accuracy,
                                             avg_lesson_accuracy))

rm(user_lesson_acc)

  #Average Practice Accuracy
user_practice_acc <- duodata |> 
  filter(session == 'practice') |> 
  group_by(user) |> 
  summarize(avg_practice_accuracy = mean(label), 
            .groups = 'keep') |> 
  ungroup()

duodata <- left_join(duodata, user_practice_acc, 
          by = join_by(user)) |>
  mutate(avg_practice_accuracy = if_else(is.na(avg_practice_accuracy),
                                               avg_session_accuracy,
                                               avg_practice_accuracy))

rm(user_practice_acc)

#Average Accuracy per User by Format
  #Reverse_Translate
user_rever_t_acc <- duodata |> 
  filter(format == 'reverse_translate') |> 
  group_by(user) |> 
  summarize(avg_reverse_trans_accuracy = mean(label), 
            .groups = 'keep') |> 
  ungroup()
  
duodata <- left_join(duodata, user_rever_t_acc, 
          by = join_by(user)) |>
  mutate(avg_reverse_trans_accuracy = if_else(is.na(avg_reverse_trans_accuracy),
                                                    avg_session_accuracy,
                                                    avg_reverse_trans_accuracy))

rm(user_rever_t_acc)

  #Reverse_Tap
user_rever_tap_acc <- duodata |> 
  filter(format == 'reverse_tap') |> 
  group_by(user) |> 
  summarize(avg_reverse_tap_accuracy = mean(label), 
            .groups = 'keep') |> 
  ungroup()

duodata <- left_join(duodata, user_rever_tap_acc, 
                     by = join_by(user)) |>
  mutate(avg_reverse_tap_accuracy = if_else(is.na(avg_reverse_tap_accuracy),
                                                  avg_session_accuracy,
                                                  avg_reverse_tap_accuracy))

rm(user_rever_tap_acc)

  #Listen
user_listen_acc <- duodata |> 
  filter(format == 'listen') |> 
  group_by(user) |> 
  summarize(avg_listen_accuracy = mean(label), 
            .groups = 'keep') |> 
  ungroup()
  
duodata <- left_join(duodata, user_listen_acc, 
                     by = join_by(user)) |>
  mutate(avg_listen_accuracy = if_else(is.na(avg_listen_accuracy),
                                       avg_session_accuracy,
                                       avg_listen_accuracy))

rm(user_listen_acc)
  


#TOTALS


#Total Number of of Countries by User 
duodata <- duodata |> 
  group_by(user) |> 
  mutate(country_count = str_count(countries, ",") + 1) |> 
  ungroup() 
  #dplyr::select(countries, country_count) |> #arrange(desc(country_count)) 


#Total Time Spent on App by User
user_times <- duodata |> 
  group_by(user, exercise_id) |> 
  summarize(total_time_exer = sum(time), 
            .groups = 'keep') |> 
  ungroup() |> 
  group_by(user) |> 
  summarise(total_time = mean(total_time_exer), 
            .groups = 'keep')

duodata <- left_join(duodata, user_times, by = join_by(user))
rm(user_times)


#Total Number of Exercises per User
tot_exer <- duodata |> 
  group_by(user) |> 
  summarize(total_exercises = n_distinct(exercise_id)) |> 
  ungroup()

duodata <- left_join(duodata, tot_exer, by = join_by(user))
rm(tot_exer)


#Total Number of Sessions per User
tot_sess <-  duodata |> 
  group_by(user) |> 
  summarize(total_sessions = n_distinct(session_id)) |> 
  ungroup()

duodata <- left_join(duodata, tot_sess, by = join_by(user))
rm(tot_sess)


#Total Number of Session by Type per User
  #Test
n_test <- duodata |> 
  filter(session == 'test') |> 
  group_by(user) |>
  summarize(total_test_sessions = n_distinct(session_id)) |> 
  ungroup() 

duodata <- left_join(duodata, n_test, by = join_by(user)) |> 
  mutate(total_test_sessions = if_else(is.na(total_test_sessions), 0, total_test_sessions))

rm(n_test)

  #Practice
n_practice <- duodata |> 
  filter(session == 'practice') |> 
  group_by(user) |>
  summarize(total_practice_sessions = n_distinct(session_id)) |> 
  ungroup() 

duodata <- left_join(duodata, n_practice, by = join_by(user)) |> 
  mutate(total_practice_sessions = if_else(is.na(total_practice_sessions), 0, total_practice_sessions))

rm(n_practice)

  #Lesson
n_lesson <- duodata |> 
  filter(session == 'lesson') |> 
  group_by(user) |>
  summarize(total_lesson_sessions = n_distinct(session_id)) |> 
  ungroup() 

duodata <- left_join(duodata, n_lesson, by = join_by(user)) |> 
  mutate(total_lesson_sessions = if_else(is.na(total_lesson_sessions), 0, total_lesson_sessions))

rm(n_lesson)


#Total Number of Each Format per User
  #Reverse Translate
n_rever_t <- duodata |> 
  filter(format == 'reverse_translate') |> 
  group_by(user) |>
  summarize(total_reverse_translate = n_distinct(session_id)) |> 
  ungroup()

duodata <- left_join(duodata, n_rever_t, by = join_by(user))  |> 
  mutate(total_reverse_translate = if_else(is.na(total_reverse_translate), 0, total_reverse_translate))

rm(n_rever_t)

  #Reverse_tap
n_rever_tap <- duodata |> 
  filter(format == 'reverse_tap') |> 
  group_by(user) |>
  summarize(total_reverse_tap = n_distinct(session_id)) |> 
  ungroup()

duodata <- left_join(duodata, n_rever_tap, by = join_by(user)) |> 
  mutate(total_reverse_tap = if_else(is.na(total_reverse_tap), 0, total_reverse_tap))

rm(n_rever_tap)

  #Listen
n_listen <- duodata |> 
  filter(format == 'listen') |> 
  group_by(user) |>
  summarize(total_listen = n_distinct(session_id)) |> 
  ungroup() 

duodata <- left_join(duodata, n_listen, by = join_by(user)) |> 
  mutate(total_listen = if_else(is.na(total_listen), 0, total_listen))

rm(n_listen)


  
#OTHER


#Get Number of Days Skipped by User
skipped <- duodata |>
  mutate(days_round_down = floor(days)) |> 
  group_by(user, days_round_down) |> 
  summarise(.groups = 'keep') |>
  ungroup() |> 
  mutate(days_skipped_user = days_round_down - dplyr::lag(days_round_down) - 1) |> 
  ungroup() |> 
  mutate(days_skipped_user = if_else(is.na(days_skipped_user) | days_skipped_user < 0, 
                                     0, 
                                     days_skipped_user))

duodata <- left_join(duodata |> mutate(days_round_down = floor(days)), 
          skipped, 
          by = join_by(user, days_round_down)) |> 
  dplyr::select(-days_round_down) 

rm(skipped)

#Get Last Day User Used App
duodata <- duodata |> 
  group_by(user) |> 
  mutate(drop_day = max(floor(days))) |> 
  ungroup()

#Accuracy on their last day
duodata <- duodata |> 
  filter(floor(days) == drop_day) |>
  group_by(user) |> 
  mutate(last_day_accuracy = mean(label)) |> 
  ungroup()
```

```{r restructure-data}
#Removing Variables not included in our final analysis 
duodata <- duodata |> dplyr::select(-countries, 
                                    -token,
                                    -part_of_speech,
                                    -dependency_label,
                                    -dependency_edge_head,
                                    -token_index,
                                    -instance_id,
                                    -exercise_id, 
                                    -days, 
                                    -exercise_index, 
                                    -client, 
                                    -session, 
                                    -format, 
                                    -time, 
                                    -session_id,
                                    -label)


#Check New Unit of Analysis (should be 2585 rows)
distinct(duodata)

#Removing Duplicated Rows (each row is still based on the tokens, so there are duplicates)
duodata <- distinct(duodata)

#Find duplicated columns
duplicated_columns <- duplicated(as.list(duodata))

#Show the names of duplicated columns
#colnames(duodata[duplicated_columns])

#Remove the duplicated columns
duodata <- duodata[, !duplicated_columns]
```

```{r check-new-distributions}
duodata |> 
  pivot_longer(cols = where(is.numeric), 
               names_to = "variable", 
               values_to = "value") |> 
  ggplot() + 
  geom_histogram(aes(value)) + 
  facet_wrap(. ~ variable, scales = "free") 
```

# Examine Introduced Missing Data

```{r new-missing}
#NOTE: No longer sampling due to reduced size of dataset from aggregation
vis_miss(duodata, 
         show_perc = TRUE) 
miss_var_summary(duodata)
#No Missing Data! 
```

# Explore Data

```{r data-viz-for-stories}
duodata |> 
  ggplot(aes(x = drop_day)) + 
  geom_histogram(col = 'white',
                 fill = "#7ac70c") + 
  labs(title = 'User Churn Over Time',
       subtitle = 'Number of Users Returning to Duolingo Each Day Decreases Over Time', 
       x = 'Number of Days a User Lasts', 
       y = 'Number of Users Lost') +
  theme_minimal()


duodata |> 
  #filter(days_skipped_user > 0) |> 
  ggplot(aes(x = days_skipped_user)) + 
  geom_histogram(fill = "#7ac70c") + 
  labs(title = 'Number of Days Users Skipped',
       subtitle = 'Most users never skip a day', 
       x = 'Number of Days Skipped', 
       y = 'Number of Users') +
  scale_y_continuous(labels = ~ format(.x, scientific = FALSE)) +
  theme_minimal() 
```

```{r get-response-mean-sd}
response_mean <- mean(duodata$drop_day)
response_sd <- sd(duodata$drop_day)
```

# Dimension Reduction

```{r standardize}
duodata <- duodata |> 
  mutate(across(where(is.numeric), scale),
         across(where(is.numeric), as.vector))
```

```{r pca}
duo_pca <- PCA(dplyr::select(duodata, where(is.numeric)), ncp = 10)
```

```{r examine-PCA}
fviz_eig(duo_pca, addlabels = TRUE, barfill = '#7ac70c')

var <- get_pca_var(duo_pca)

corrplot(var$cor, 
         tl.col = "black", 
         method = "color")

corrplot(var$cos2, 
         is.corr = FALSE, 
         tl.col = "black", 
         method = "color")
```

```{r viz-pca-var-importance}
var <- get_pca_var(duo_pca)

t(var$coord) |> 
  as_tibble(rownames = "NA") |> 
  rename(dimension = `NA`) |> 
  pivot_longer(cols = -starts_with("dimension"),
               names_to = "variable",
               values_to = "value") |> 
  mutate(importance = value * value,
         dimension = as.factor(dimension)) |> 
  group_by(dimension) |>
  slice_max(importance, n = 10) |>
  ungroup() |>
  mutate(variable = reorder_within(variable,
                                   by = value,
                                   within = dimension)) |>  
  filter(dimension == "Dim.1" |
           dimension == "Dim.2" |
           dimension == "Dim.3" |
           dimension == "Dim.4") |> 
  # mutate(dimension = case_when(dimension == "Dim.1" ~ "1.Accuracy",
  #                              dimension == "Dim.2" ~ '2.Investment', 
  #                              dimension == "Dim.3" ~ '3.Rushedness', 
  #                              dimension == "Dim.4" ~ '4.Burnout')) |> 
  ggplot() +
  geom_col(aes(y = value,
               x = variable, 
               fill = value > 0)) +
  facet_wrap(~ dimension,
             scales = "free_y") +
  scale_x_reordered() + 
  coord_flip() +
  guides(fill = "none") + 
  labs(title = 'How do these variables relate?', 
       subtitle = 'Duolingo Latent Variable Component Analysis')
```

```{r join-pca-values-to-data}
#Assign PCA Values to Observations
dims <- get_pca_ind(duo_pca)
duodata_pca <- duodata |> 
  mutate(pca_dim1 = dims$coord[,1],
         pca_dim2 = dims$coord[,2],
         pca_dim3 = dims$coord[,3],
         pca_dim4 = dims$coord[,4])

duodata <- duodata |> 
  mutate(pca_dim1 = dims$coord[,1],
         pca_dim2 = dims$coord[,2],
         pca_dim3 = dims$coord[,3],
         pca_dim4 = dims$coord[,4])
```

# Create Clusters

## Hierarchical

```{r hierarchical}
duo_diff <- dist(dplyr::select(duodata, 
                               -user, 
                               -starts_with("pca_dim")), method = "euclidean")
duo_hc_c <- hclust(duo_diff, method = "ward.D")

duo_dend <- as.dendrogram(duo_hc_c)|> 
  color_labels(k = 3)  |> 
  color_branches(k = 3)

duo_dend |> 
  set("labels_cex", 0.5) |> 
  plot(main = "User Engagement Clusters")
```

```{r assign-hc-cluster}
hc_cut <- cutree(duo_hc_c, k = 3)

duodata$hc_cluster <- hc_cut
dplyr::select(duodata, user, hc_cluster)
```

```{r viz-hc-pca-dims-by-clusters}
duodata |> 
  mutate(hc_cluster = as.factor(hc_cluster)) |> 
  ggplot(aes(x = pca_dim1, 
             y = pca_dim2)) + 
  geom_point(aes(color = hc_cluster)) + 
  geom_vline(xintercept = 0) + 
  geom_hline(yintercept = 0) + 
  labs(title = 'Duolingo User Clusters by PCA Dimension', 
       subtitle = 'Front View', 
       x = 'PCA Dimension 1 - Accuracy', 
       y = 'PCA Dimension 2 - Time Investment') + 
  theme_minimal() +
  theme(legend.position = 'bottom')

duodata |> 
  mutate(hc_cluster = as.factor(hc_cluster)) |> 
  ggplot(aes(x = pca_dim1, 
             y = pca_dim3)) + 
  geom_point(aes(color = hc_cluster)) + 
  geom_vline(xintercept = 0) + 
  geom_hline(yintercept = 0) + 
  labs(title = 'Duolingo User Clusters by PCA Dimension',
       subtitle = 'Bottom View', 
       x = 'PCA Dimension 1 - Accuracy', 
       y = 'PCA Dimension 3 - Rushedness') + 
  theme_minimal() +
  theme(legend.position = 'bottom')

duodata |> 
  mutate(hc_cluster = as.factor(hc_cluster)) |> 
  ggplot(aes(x = pca_dim3, 
             y = pca_dim2)) + 
  geom_point(aes(color = hc_cluster)) + 
  geom_vline(xintercept = 0) + 
  geom_hline(yintercept = 0) + 
  labs(title = 'Duolingo User Clusters by PCA Dimension', 
       subtitle = 'Side View', 
       x = 'PCA Dimension 3 -Rushedness', 
       y = 'PCA Dimension 2 - Time Investment') + 
  theme_minimal() +
  theme(legend.position = 'bottom') 
```

```{r examine-var-importance}
#PCA Variable Averages
cluster_averages <- duodata |>
  dplyr::select(hc_cluster, starts_with("pca_dim")) |> 
  group_by(hc_cluster) |>
  summarize(across(where(is.numeric), mean)) |>
  ungroup() |>
  pivot_longer(-hc_cluster, 
               names_to = "engagement_metrics", 
               values_to = "value")

cluster_averages |> 
  mutate(engagement_metrics = case_when(engagement_metrics == "pca_dim1" ~ "1.Accuracy",
                               engagement_metrics == "pca_dim2" ~ '2.Investment', 
                               engagement_metrics == "pca_dim3" ~ '3.Rushedness', 
                               engagement_metrics == "pca_dim4" ~ '4.Burnout')) |> 
ggplot(aes(x = engagement_metrics, 
           y = value, 
           fill = value > 0)) + 
  geom_col() + 
  scale_fill_manual(values = c('darkgrey', "#7ac70c")) +
  #geom_text(aes(label = round(value, 2)), 
  #          position = position_dodge(width = 0.9), 
  #          hjust = -0.2, vjust = 0.5) +
  coord_flip() +
  facet_wrap(~ hc_cluster) +
  labs(x = "Engagement Metric", 
       y = "Value", 
       title = "Engagement Metrics by Cluster") +
  theme(legend.position = "none") 



#Non-PCA Variables Average
cluster_averages <- duodata |>
  dplyr::select(-starts_with("pca_dim")) |>
  group_by(hc_cluster) |>
  summarize(across(where(is.numeric), mean)) |>
  ungroup() |>
  pivot_longer(-hc_cluster, 
               names_to = "engagement_metrics", 
               values_to = "value")

ggplot(cluster_averages, aes(x = engagement_metrics, 
                             y = value, 
                             fill = value > 0)) + 
  geom_col() +
  scale_fill_manual(values = c('darkgrey', "#7ac70c")) +
  #geom_text(aes(label = round(value, 2)), 
  #          position = position_dodge(width = 0.9), 
  #          hjust = -0.2, vjust = 0.5) +
  coord_flip() +
  facet_grid(~ hc_cluster) +
  labs(x = "Engagement Metric", 
       y = "Value", 
       title = "Engagement Metrics by Cluster") +
  theme(legend.position = "none")
```

# Build Predictive Model - HC

```{r split-data}
#Removing Cluster Color Variable from the 3D plot (proxying as the cluster)
duodata <- dplyr::select(duodata, -color)

#NOTE: Data already standardized
set.seed(1234) 
train <- sample_frac(duodata, 0.8) 
test <- filter(duodata, !duodata$user %in% train$user) 
```

```{r build-samples}
#Build without PCA Dimensions and without Clusters
train_samp1 <- train |> dplyr::select(-user,
                                -starts_with("pca_dim"),
                                -hc_cluster)
test_samp1 <- test |> dplyr::select(-user,
                              -starts_with("pca_dim"),
                              -hc_cluster)

#Build with ONLY PCA
train_samp_pca <- train |> dplyr::select(drop_day,
                                starts_with("pca_dim"))
test_samp_pca <- test |> dplyr::select(drop_day,
                              starts_with("pca_dim"))

#Build with ONLY GMM Cluster
train_samp_clust <- train |> dplyr::select(drop_day,
                                hc_cluster)
test_samp_clust <- test |> dplyr::select(drop_day,
                              hc_cluster)

#Build with PCA AND GMM
train_samp_both <- train |> dplyr::select(drop_day,
                                hc_cluster,
                                starts_with("pca_dim"))
test_samp_both <- test |> dplyr::select(drop_day,
                              hc_cluster,
                              starts_with("pca_dim"))
```

```{r build-models}
trControl = trainControl(method = "cv",
                         number = 10)

rmse_results <- tibble(samp = character(), 
                       min_rmse = double())

#First
set.seed(1234)
m_boost_rf_1 <- train(drop_day ~ .,
                    data = train_samp1, 
                    method = "xgbTree", 
                    trControl = trControl, 
                    verbose = FALSE, 
                    verbosity = 0)

rmse_results <- bind_rows(rmse_results, 
                          tibble(samp = 'train_samp1', 
                                 min_rmse = min(m_boost_rf_1$resample$RMSE)))

#Second
set.seed(1234)
m_boost_rf_pca <- train(drop_day ~ .,
                    data = train_samp_pca, 
                    method = "xgbTree", 
                    trControl = trControl, 
                    verbose = FALSE, 
                    verbosity = 0) 

rmse_results <- bind_rows(rmse_results, 
                          tibble(samp = 'train_samp_pca', 
                                 min_rmse = min(m_boost_rf_pca$resample$RMSE)))

#Third
set.seed(1234)
m_boost_rf_hc <- train(drop_day ~ .,
                    data = train_samp_clust, 
                    method = "xgbTree", 
                    trControl = trControl, 
                    verbose = FALSE, 
                    verbosity = 0)

rmse_results <- bind_rows(rmse_results, 
                          tibble(samp = 'train_samp_clust', 
                                 min_rmse = min(m_boost_rf_hc$resample$RMSE)))


#Fourth
set.seed(1234)
m_boost_rf_both <- train(drop_day ~ .,
                    data = train_samp_both, 
                    method = "xgbTree", 
                    trControl = trControl, 
                    verbose = FALSE, 
                    verbosity = 0)

rmse_results <- bind_rows(rmse_results, 
                          tibble(samp = 'train_samp_both', 
                                 min_rmse = min(m_boost_rf_both$resample$RMSE)))
```

```{r model-results}
#saved_result <- rmse_results
rmse_results <- saved_result 
rmse_results <- rmse_results |> 
  mutate(samp = case_when(samp == 'train_samp1' ~ "No Groupings", 
                          samp == 'train_samp_pca' ~ "PCA Dimensions", 
                          samp == 'train_samp_clust' ~ "HC Clusters", 
                          samp == 'train_samp_both' ~ "Both Dimension Reductions"), 
         min_rmse = 1 - min_rmse, 
         samp = as.factor(samp)) 

rmse_results |> 
  ggplot(aes(x = forcats::fct_reorder(samp, min_rmse), 
             y = min_rmse, 
             fill = samp)) + 
  geom_col() + 
  geom_text(aes(label = round(min_rmse, 4)), 
            position = position_dodge(width = 0.9), 
            vjust = 0) + 
  labs(title = "XGBoost Model Performance on Different Samples", 
       subtitle = 'Model Performance Given as 1-Standardized_RMSE', 
       x = 'Sample', 
       y = '1 - RMSE') +
  theme_minimal() +
  theme(legend.position = 'none') 


rmse_results |> 
  ggplot(aes(x = forcats::fct_reorder(samp, min_rmse), 
             y = min_rmse)) + 
  geom_col() + 
  geom_col(data = rmse_results |> filter(samp %in% c("PCA Dimensions", 
                                                     "Both Dimension Reductions")), 
           fill = "#7ac70c") + 
  geom_text(aes(label = round(min_rmse, 4)), 
            position = position_dodge(width = 0.9), 
            vjust = 0) + 
  labs(title = "XG Boost Model Performance on Different Samples", 
       subtitle = 'Model Performance Given as 1-Standardized_RMSE', 
       x = 'Sample', 
       y = '1 - RMSE') +
  theme_minimal() +
  theme(legend.position = 'none') 
```

```{r info-xgboostz}
plot(m_boost_rf_1)
plot(m_boost_rf_pca)
plot(m_boost_rf_hc)
plot(m_boost_rf_both)

varImp(m_boost_rf_1)
varImp(m_boost_rf_pca)
#varImp(m_boost_rf_hc)
varImp(m_boost_rf_both)
```

```{r predict-xgboost}
predicted_drop_train_rf <- predict(m_boost_rf_both, train)
predicted_drop_test_rf <- predict(m_boost_rf_both, test)

train_predictions <- tibble(predicted_drop = predicted_drop_train_rf,
                            drop = train$drop_day, 
                            source = 'train')

test_predictions <- tibble(predicted_drop = predicted_drop_test_rf,
                           drop = test$drop_day,
                           source = 'test')

all_predictions <- bind_rows(train_predictions, test_predictions)

ggplot(all_predictions, 
       aes(x = drop,
           y = predicted_drop, 
           color = source)) +
  geom_point() +
  geom_abline(aes(intercept = 0, 
                  slope = 1), 
              lty = 2) +
  theme_bw()
```

```{r unstandardize-predictions}
all_predictions |> 
  mutate(predicted_drop = predicted_drop*response_sd + response_mean, 
         drop = drop*response_sd + response_mean) |> 
  ggplot(aes(x = drop,
           y = predicted_drop, 
           color = source)) +
  geom_point() +
  geom_abline(aes(intercept = 0, 
                  slope = 1), 
              lty = 2) +
  theme_bw()
```

```{r importance-viz}
varImp(m_boost_rf_both)$importance |> 
  as.data.frame() |> 
  rownames_to_column() |> 
  arrange(Overall) |>
  mutate(rowname = case_when(rowname == 'pca_dim1' ~ 'Accuracy', 
                             rowname == 'pca_dim2' ~ 'Investment', 
                             rowname == 'pca_dim3' ~ 'Rushed-ness', 
                             rowname == 'pca_dim4' ~ 'Burnout', 
                             rowname == 'hc_cluster' ~ 'Cluster')) |> 
  ggplot(aes(x = forcats::fct_reorder(rowname, Overall), 
             y = Overall)) +
  geom_col(aes(fill = factor(rowname, 
                             levels = c('Burnout', 'Rushed-ness')))) +
  scale_fill_manual(values = c('#7ac70c', '#7ac70c')) +
  coord_flip() + 
  labs(title = "Variable Importance for PCA + Cluster Model", 
       subtitle = 'Burnout and Rushedness Dimensions prove to be the most important', 
       x = 'Variable', 
       y = 'Overall Importance') +
  theme_minimal() +
  theme(legend.position = 'none')
```

```{r plotly}
fig <- plot_ly(duodata, 
               x = ~pca_dim3, 
               y = ~pca_dim1, 
               z = ~pca_dim2, 
               color = ~as.factor(hc_cluster), 
               size = ~drop_day)
fig <- fig |> add_markers()
fig <- fig |> layout(scene = list(xaxis = list(title = 'Dim 3 - Rushed-ness'),
                     yaxis = list(title = 'Dim 1 - Accuracy'),
                     zaxis = list(title = 'Dim 2 - Time Investment')))

fig
```

## Create Clusters - GMM

```{r build-gmms}
#Build GMM with PCA
set.seed(1234)
gmm_pca <- Mclust(data = dplyr::select(duodata_pca,
                                       starts_with("pca_dim")))
summary(gmm_pca) 
```

```{r assign-clusters}
#Attach clusters to data
gmm_preds <- predict(gmm_pca) 
duodata_pca_gmm <- bind_cols(duodata_pca, gmm_preds$classification) 

#Rename gmm_cluster column
duodata_pca_gmm <- duodata_pca_gmm |> 
  rename(gmm_cluster = ...31) 
```

```{r}
plot(gmm_1, what = 'uncertainty')

max_probs <- tibble(max_prob = double())

for (n in 1:length(duodata_pca_gmm$user)){
  max_probs <- bind_rows(max_probs, 
                         tibble(max_prob = max(gmm_preds$z[n,])))
}  

duodata_pca_gmm$max_prob <- max_probs$max_prob

duodata_pca_gmm |> dplyr::select(user, max_prob) |> 
  ggplot(aes(x = max_prob)) + 
  geom_histogram(fill = '#2952A3') + 
  labs(title = 'Spread of Max Probabilities from GMM', 
       x = 'Highest Probability of Cluster Assignment', 
       y = 'Number of Observations') + 
  theme_minimal()
```

```{r viz-pca-dims-by-clusters}
duodata_pca_gmm |> 
  mutate(gmm_cluster = as.factor(gmm_cluster)) |> 
  ggplot(aes(x = pca_dim1, 
             y = pca_dim2)) + 
  geom_point(aes(color = gmm_cluster)) + 
  geom_vline(xintercept = 0) + 
  geom_hline(yintercept = 0) + 
  labs(title = 'Duolingo User Clusters by PCA Dimension', 
       subtitle = 'Front View', 
       x = 'PCA Dimension 1 - Accuracy', 
       y = 'PCA Dimension 2 - Time Investment') + 
  theme_minimal() +
  theme(legend.position = 'bottom') 

duodata_pca_gmm |> 
  mutate(gmm_cluster = as.factor(gmm_cluster)) |> 
  ggplot(aes(x = pca_dim1, 
             y = pca_dim3)) + 
  geom_point(aes(color = gmm_cluster)) + 
  geom_vline(xintercept = 0) + 
  geom_hline(yintercept = 0) + 
  labs(title = 'Duolingo User Clusters by PCA Dimension',
       subtitle = 'Bottom View', 
       x = 'PCA Dimension 1 - Accuracy', 
       y = 'PCA Dimension 3 - Rushedness') + 
  theme_minimal() +
  theme(legend.position = 'bottom')

duodata_pca_gmm |> 
  mutate(gmm_cluster = as.factor(gmm_cluster)) |> 
  ggplot(aes(x = pca_dim3, 
             y = pca_dim2)) + 
  geom_point(aes(color = gmm_cluster)) + 
  geom_vline(xintercept = 0) + 
  geom_hline(yintercept = 0) + 
  labs(title = 'Duolingo User Clusters by PCA Dimension', 
       subtitle = 'Side View', 
       x = 'PCA Dimension 3 - Rushedness', 
       y = 'PCA Dimension 2 - Time Investment') + 
  theme_minimal() +
  theme(legend.position = 'bottom')
```

```{r examine-var-importance}
#PCA Variable Averages
cluster_averages <- duodata_pca_gmm |>
  dplyr::select(gmm_cluster, starts_with("pca_dim")) |> 
  group_by(gmm_cluster) |>
  summarize(across(where(is.numeric), mean)) |>
  ungroup() |>
  pivot_longer(-gmm_cluster, 
               names_to = "engagement_metrics", 
               values_to = "value") 

cluster_averages |> 
  mutate(engagement_metrics = case_when(engagement_metrics == "pca_dim1" ~ "1.Accuracy",
                               engagement_metrics == "pca_dim2" ~ '2.Investment', 
                               engagement_metrics == "pca_dim3" ~ '3.Rushedness', 
                               engagement_metrics == "pca_dim4" ~ '4.Burnout')) |>
ggplot(aes(x = engagement_metrics, 
           y = value, 
           fill = value > 0)) + 
  geom_col() +
  scale_fill_manual(values = c('darkgrey', "#7ac70c")) +
  geom_text(aes(label = round(value, 2)), 
            position = position_dodge(width = 0.9), 
            hjust = -0.2, vjust = 0.5) +
  coord_flip() +
  facet_wrap(~ gmm_cluster) +
  labs(x = "Engagement Metric", 
       y = "Value", 
       title = "Engagement Metrics by Cluster") +
  theme(legend.position = "none")



#Non-PCA Variables Average
cluster_averages <- duodata_pca_gmm |>
  dplyr::select(-starts_with("pca_dim")) |>
  group_by(gmm_cluster) |>
  summarize(across(where(is.numeric), mean)) |>
  ungroup() |>
  pivot_longer(-gmm_cluster, 
               names_to = "engagement_metrics", 
               values_to = "value")

ggplot(cluster_averages, aes(x = engagement_metrics, 
                             y = value, 
                             fill = value > 0)) + 
  geom_col() +
  scale_fill_manual(values = c('darkgrey', "#7ac70c")) +
  geom_text(aes(label = round(value, 2)), 
            position = position_dodge(width = 0.9), 
            hjust = -0.2, vjust = 0.5) +
  coord_flip() +
  facet_grid(~ gmm_cluster) +
  labs(x = "Engagement Metric", 
       y = "Value", 
       title = "Engagement Metrics by Cluster") +
  theme(legend.position = "none")
```

# Build Predictive Model - GMM

```{r split-data}
#Remove color variable from 3D plot
duodata_pca_gmm <- dplyr::select(duodata_pca_gmm, -color)

#NOTE: Data already standardized
set.seed(1234) 
train <- sample_frac(duodata_pca_gmm, 0.8) 
test <- filter(duodata_pca_gmm, !duodata_pca_gmm$user %in% train$user) 
```

```{r build-samples}
#Build without PCA Dimensions and without Clusters
train_samp1 <- train |> dplyr::select(-user,
                                -starts_with("pca_dim"),
                                -gmm_cluster)
test_samp1 <- test |> dplyr::select(-user,
                              -starts_with("pca_dim"),
                              -gmm_cluster)

#Build with ONLY PCA
train_samp_pca <- train |> dplyr::select(drop_day,
                                starts_with("pca_dim"))
test_samp_pca <- test |> dplyr::select(drop_day,
                              starts_with("pca_dim"))

#Build with ONLY GMM Cluster
train_samp_clust <- train |> dplyr::select(drop_day,
                                gmm_cluster)
test_samp_clust <- test |> dplyr::select(drop_day,
                              gmm_cluster)

#Build with PCA AND GMM
train_samp_both <- train |> dplyr::select(drop_day,
                                gmm_cluster,
                                starts_with("pca_dim"))
test_samp_both <- test |> dplyr::select(drop_day,
                              gmm_cluster,
                              starts_with("pca_dim"))
```

```{r build-models}
trControl = trainControl(method = "cv",
                         number = 10)

rmse_results <- tibble(samp = character(), 
                       min_rmse = double())

#First
set.seed(1234)
m_boost_rf_1 <- train(drop_day ~ .,
                    data = train_samp1, 
                    method = "xgbTree", 
                    trControl = trControl, 
                    verbose = FALSE, 
                    verbosity = 0)

rmse_results <- bind_rows(rmse_results, 
                          tibble(samp = 'train_samp1', 
                                 min_rmse = min(m_boost_rf_1$resample$RMSE)))

#Second
set.seed(1234)
m_boost_rf_pca <- train(drop_day ~ .,
                    data = train_samp_pca, 
                    method = "xgbTree", 
                    trControl = trControl, 
                    verbose = FALSE, 
                    verbosity = 0) 

rmse_results <- bind_rows(rmse_results, 
                          tibble(samp = 'train_samp_pca', 
                                 min_rmse = min(m_boost_rf_pca$resample$RMSE)))

#Third
set.seed(1234)
m_boost_rf_hc <- train(drop_day ~ .,
                    data = train_samp_clust, 
                    method = "xgbTree", 
                    trControl = trControl, 
                    verbose = FALSE, 
                    verbosity = 0)

rmse_results <- bind_rows(rmse_results, 
                          tibble(samp = 'train_samp_clust', 
                                 min_rmse = min(m_boost_rf_hc$resample$RMSE)))


#Fourth
set.seed(1234)
m_boost_rf_both <- train(drop_day ~ .,
                    data = train_samp_both, 
                    method = "xgbTree", 
                    trControl = trControl, 
                    verbose = FALSE, 
                    verbosity = 0)

rmse_results <- bind_rows(rmse_results, 
                          tibble(samp = 'train_samp_both', 
                                 min_rmse = min(m_boost_rf_both$resample$RMSE)))
```

```{r model-results}
#saved_result <- rmse_results
#rmse_results <- saved_result 
rmse_results <- rmse_results |> 
  mutate(samp = case_when(samp == 'train_samp1' ~ "No Groupings", 
                          samp == 'train_samp_pca' ~ "PCA Dimensions", 
                          samp == 'train_samp_clust' ~ "GMM Clusters", 
                          samp == 'train_samp_both' ~ "Both Dimension Reductions"), 
         min_rmse = 1 - min_rmse, 
         samp = as.factor(samp)) 

rmse_results |> 
  ggplot(aes(x = forcats::fct_reorder(samp, min_rmse), 
             y = min_rmse, 
             fill = samp)) + 
  geom_col() + 
  geom_text(aes(label = round(min_rmse, 4)), 
            position = position_dodge(width = 0.9), 
            vjust = 0) + 
  labs(title = "XGBoost Model Performance on Different Samples", 
       subtitle = 'Model Performance Given as 1-Standardized_RMSE', 
       x = 'Sample', 
       y = '1 - RMSE') +
  theme_minimal() +
  theme(legend.position = 'none') 


rmse_results |> 
  ggplot(aes(x = forcats::fct_reorder(samp, min_rmse), 
             y = min_rmse)) + 
  geom_col() + 
  geom_col(data = rmse_results |> filter(samp %in% c("PCA Dimensions", 
                                                     "Both Dimension Reductions")), 
           fill = "#7ac70c") + 
  geom_text(aes(label = round(min_rmse, 4)), 
            position = position_dodge(width = 0.9), 
            vjust = 0) + 
  labs(title = "XG Boost Model Performance on Different Samples", 
       subtitle = 'Model Performance Given as 1-Standardized_RMSE', 
       x = 'Sample', 
       y = '1 - RMSE') +
  theme_minimal() +
  theme(legend.position = 'none') 
```

```{r info-boost-rf}
plot(m_boost_rf_1)
plot(m_boost_rf_pca)
plot(m_boost_rf_hc)
plot(m_boost_rf_both)

varImp(m_boost_rf_1)
varImp(m_boost_rf_pca)
#varImp(m_boost_rf_hc)
varImp(m_boost_rf_both)
```

```{r predict-rf}
predicted_drop_train_rf <- predict(m_boost_rf_both, train)
predicted_drop_test_rf <- predict(m_boost_rf_both, test)

train_predictions <- tibble(predicted_drop = predicted_drop_train_rf,
                            drop = train$drop_day, 
                            source = 'train')

test_predictions <- tibble(predicted_drop = predicted_drop_test_rf,
                           drop = test$drop_day,
                           source = 'test')

all_predictions <- bind_rows(train_predictions, test_predictions)

ggplot(all_predictions, 
       aes(x = drop,
           y = predicted_drop, 
           color = source)) +
  geom_point() +
  geom_abline(aes(intercept = 0, 
                  slope = 1), 
              lty = 2) +
  theme_bw()
```

```{r}
varImp(m_boost_rf_both)$importance |> 
  as.data.frame() |> 
  rownames_to_column() |> 
  arrange(Overall) |>
  mutate(rowname = case_when(rowname == 'pca_dim1' ~ 'Accuracy', 
                             rowname == 'pca_dim2' ~ 'Investment', 
                             rowname == 'pca_dim3' ~ 'Rushed-ness', 
                             rowname == 'pca_dim4' ~ 'Burnout', 
                             rowname == 'gmm_cluster' ~ 'Cluster')) |> 
  ggplot(aes(x = forcats::fct_reorder(rowname, Overall), 
             y = Overall)) +
  geom_col(aes(fill = factor(rowname, 
                             levels = c('Burnout', 'Rushed-ness')))) +
  scale_fill_manual(values = c('#7ac70c', '#7ac70c')) +
  coord_flip() + 
  labs(title = "Variable Importance for PCA + Cluster Model", 
       subtitle = 'Burnout and Rushedness Dimensions prove to be the most important', 
       x = 'Variable', 
       y = 'Overall Importance') +
  theme_minimal() +
  theme(legend.position = 'none')
```

```{r plotly}
fig <- plot_ly(duodata_pca_gmm, 
               x = ~pca_dim3, 
               y = ~pca_dim1, 
               z = ~pca_dim2, 
               color = ~as.factor(gmm_cluster), 
               size = ~drop_day)
fig <- fig |> add_markers()
fig <- fig |> layout(scene = list(xaxis = list(title = 'Dim 3 - Rushed-ness'),
                     yaxis = list(title = 'Dim 1 - Accuracy'),
                     zaxis = list(title = 'Dim 2 - Time Investment')))

fig
```
